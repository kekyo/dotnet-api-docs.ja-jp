<Type Name="RecognizeCompletedEventArgs" FullName="System.Speech.Recognition.RecognizeCompletedEventArgs">
  <Metadata><Meta Name="ms.openlocfilehash" Value="a186436bba18e5a077ff36125f45bc93be297230" /><Meta Name="ms.sourcegitcommit" Value="16d2d159872fd213cae4b8f371d7ae9c8b027c89" /><Meta Name="ms.translationtype" Value="HT" /><Meta Name="ms.contentlocale" Value="ja-JP" /><Meta Name="ms.lasthandoff" Value="11/17/2018" /><Meta Name="ms.locfileid" Value="51882209" /></Metadata><TypeSignature Language="C#" Value="public class RecognizeCompletedEventArgs : System.ComponentModel.AsyncCompletedEventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit RecognizeCompletedEventArgs extends System.ComponentModel.AsyncCompletedEventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizeCompletedEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class RecognizeCompletedEventArgs&#xA;Inherits AsyncCompletedEventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class RecognizeCompletedEventArgs : System::ComponentModel::AsyncCompletedEventArgs" />
  <TypeSignature Language="F#" Value="type RecognizeCompletedEventArgs = class&#xA;    inherit AsyncCompletedEventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.ComponentModel.AsyncCompletedEventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary><span data-ttu-id="eeb6f-101"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> または <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> オブジェクトによって発生する <see langword="RecognizeCompleted" /> イベントにデータを提供します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-101">Provides data for the <see langword="RecognizeCompleted" /> event raised by a <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> or a <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object.</span></span></summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="eeb6f-102">インスタンス<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted>場合は、作成、<xref:System.Speech.Recognition.SpeechRecognitionEngine>または<xref:System.Speech.Recognition.SpeechRecognizer>オブジェクトその`SpeechRecognized`イベントの完了後、`RecognizeAsync`操作。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-102">An instance of <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> is created when the <xref:System.Speech.Recognition.SpeechRecognitionEngine> or the <xref:System.Speech.Recognition.SpeechRecognizer> object raises its `SpeechRecognized` event after completing a `RecognizeAsync` operation.</span></span> <span data-ttu-id="eeb6f-103">音声認識イベントに関する詳細については、次を参照してください。[音声認識イベントを使用した](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-103">For more information about speech recognition events, see [Using Speech Recognition Events](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="eeb6f-104">次の例は、音声認識文法の非同期音声認識を実行を使用して、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType>インプロセス レコグナイザーを持つメソッド。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-104">The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> method with the in-process recognizer.</span></span> <span data-ttu-id="eeb6f-105">この例では<xref:System.Speech.Recognition.Choices>と<xref:System.Speech.Recognition.GrammarBuilder>に構築する前に、音声認識文法を作成するオブジェクト、<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-105">The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object.</span></span> <span data-ttu-id="eeb6f-106">ハンドラーを<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType>イベントは、コンソールに認識操作に関する情報を出力します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-106">A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> event outputs information about the recognition operation to the console.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
    <altmember cref="M:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync" />
    <altmember cref="T:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs" />
  </Docs>
  <Members>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="eeb6f-107"><see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /> イベントに関連付けられた入力デバイスのオーディオ ストリームの場所を取得します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-107">Gets the location in the input device's audio stream associated with the <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /> event.</span></span></summary>
        <value><span data-ttu-id="eeb6f-108"><see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /> イベントに関連付けられた入力デバイスのオーディオ ストリームの場所。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-108">The location in the input device's audio stream associated with the <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /> event.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="eeb6f-109">このプロパティは、生成されたオーディオ ストリームの入力デバイスの認識された語句の先頭の位置を参照します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-109">This property references the position at the beginning of the recognized phrase in the input device's generated audio stream.</span></span> <span data-ttu-id="eeb6f-110">これに対し、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A>プロパティ参照がオーディオ入力内の認識エンジンの位置。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-110">By contrast, the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property references the recognizer's position within its audio input.</span></span> <span data-ttu-id="eeb6f-111">これらの位置は、さまざまなであることができます。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-111">These positions can be different.</span></span> <span data-ttu-id="eeb6f-112">詳細については、次を参照してください。[音声認識イベントを使用した](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-112">For more information, see [Using Speech Recognition Events](https://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="eeb6f-113">次の例は、音声認識文法の非同期音声認識を実行を使用して、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType>インプロセス レコグナイザーを持つメソッド。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-113">The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> method with the in-process recognizer.</span></span> <span data-ttu-id="eeb6f-114">この例では<xref:System.Speech.Recognition.Choices>と<xref:System.Speech.Recognition.GrammarBuilder>に構築する前に、音声認識文法を作成するオブジェクト、<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-114">The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object.</span></span> <span data-ttu-id="eeb6f-115">ハンドラーを<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType>イベントは、コンソールに認識操作に関する情報を出力します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-115">A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> event outputs information about the recognition operation to the console.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="BabbleTimeout">
      <MemberSignature Language="C#" Value="public bool BabbleTimeout { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool BabbleTimeout" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property BabbleTimeout As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool BabbleTimeout { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.BabbleTimeout : bool" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="eeb6f-116">バブル タイムアウトで <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /> イベントが生成されたかどうかを示す値を取得します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-116">Gets a value that indicates whether a babble timeout generated the <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /> event.</span></span></summary>
        <value><span data-ttu-id="eeb6f-117"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が、<see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" /> プロパティで指定された時間よりも長い期間、バックグラウンド ノイズだけを検出した場合は <see langword="true" />。それ以外の場合は <see langword="false." /></span><span class="sxs-lookup"><span data-stu-id="eeb6f-117"><see langword="true" /> if the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> has detected only background noise for longer than was specified by its <see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" /> property; otherwise <see langword="false." /></span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 <span data-ttu-id="eeb6f-118">次の例は、音声認識文法の非同期音声認識を実行を使用して、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType>インプロセス レコグナイザーを持つメソッド。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-118">The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> method with the in-process recognizer.</span></span> <span data-ttu-id="eeb6f-119">この例では<xref:System.Speech.Recognition.Choices>と<xref:System.Speech.Recognition.GrammarBuilder>に構築する前に、音声認識文法を作成するオブジェクト、<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-119">The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object.</span></span> <span data-ttu-id="eeb6f-120">ハンドラーを<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType>イベントは、コンソールに認識操作に関する情報を出力します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-120">A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> event outputs information about the recognition operation to the console.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout" />
      </Docs>
    </Member>
    <Member MemberName="InitialSilenceTimeout">
      <MemberSignature Language="C#" Value="public bool InitialSilenceTimeout { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool InitialSilenceTimeout" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property InitialSilenceTimeout As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool InitialSilenceTimeout { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.InitialSilenceTimeout : bool" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="eeb6f-121">初期サイレント タイムアウトで <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /> イベントが生成されたかどうかを示す値を取得します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-121">Gets a value that indicates whether an initial silence timeout generated the <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" /> event.</span></span></summary>
        <value><span data-ttu-id="eeb6f-122"><see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> が、<see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" /> プロパティで指定された時間よりも長い期間、無音だけを検出した場合は <see langword="true" />。それ以外の場合は <see langword="false." /></span><span class="sxs-lookup"><span data-stu-id="eeb6f-122"><see langword="true" /> if the <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> has detected only silence for a longer time period than was specified by its <see cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" /> property; otherwise <see langword="false." /></span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Examples  
 <span data-ttu-id="eeb6f-123">次の例は、音声認識文法の非同期音声認識を実行を使用して、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType>インプロセス レコグナイザーを持つメソッド。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-123">The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> method with the in-process recognizer.</span></span> <span data-ttu-id="eeb6f-124">この例では<xref:System.Speech.Recognition.Choices>と<xref:System.Speech.Recognition.GrammarBuilder>に構築する前に、音声認識文法を作成するオブジェクト、<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-124">The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object.</span></span> <span data-ttu-id="eeb6f-125">ハンドラーを<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType>イベントは、コンソールに認識操作に関する情報を出力します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-125">A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> event outputs information about the recognition operation to the console.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout" />
      </Docs>
    </Member>
    <Member MemberName="InputStreamEnded">
      <MemberSignature Language="C#" Value="public bool InputStreamEnded { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool InputStreamEnded" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property InputStreamEnded As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool InputStreamEnded { bool get(); };" />
      <MemberSignature Language="F#" Value="member this.InputStreamEnded : bool" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="eeb6f-126">入力ストリームが終了しているかどうかを示す値を取得します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-126">Gets a value indicating whether the input stream ended.</span></span></summary>
        <value><span data-ttu-id="eeb6f-127">レコグナイザーへのオーディオ入力がなくなった場合は <see langword="true" />。それ以外の場合は <see langword="false" />。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-127"><see langword="true" /> if the recognizer no longer has audio input; otherwise, <see langword="false" />.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="eeb6f-128">認識エンジンでは、このプロパティを設定`true`ファイル認識エンジンの入力ストリームを提供して、ファイルの末尾に到達します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-128">The recognizer sets this property to `true` when a file provides the input stream for the recognizer and the end of the file is reached.</span></span> <span data-ttu-id="eeb6f-129">入力ストリームの末尾は、成功した認識操作と一致できます。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-129">The end of the input stream can coincide with a successful recognition operation.</span></span> <span data-ttu-id="eeb6f-130">入力ストリームとしてファイルを使用する方法の詳細については、次を参照してください。、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A>と<xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-130">For more information about using a file as the input stream, see the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> methods.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="eeb6f-131">次の例は、音声認識文法の非同期音声認識を実行を使用して、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType>インプロセス レコグナイザーを持つメソッド。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-131">The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> method with the in-process recognizer.</span></span> <span data-ttu-id="eeb6f-132">この例では<xref:System.Speech.Recognition.Choices>と<xref:System.Speech.Recognition.GrammarBuilder>に構築する前に、音声認識文法を作成するオブジェクト、<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-132">The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object.</span></span> <span data-ttu-id="eeb6f-133">ハンドラーを<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType>イベントは、コンソールに認識操作に関する情報を出力します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-133">A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> event outputs information about the recognition operation to the console.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      </Docs>
    </Member>
    <Member MemberName="Result">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult Result { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognitionResult Result" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.RecognizeCompletedEventArgs.Result" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Result As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognitionResult ^ Result { System::Speech::Recognition::RecognitionResult ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Result : System.Speech.Recognition.RecognitionResult" Usage="System.Speech.Recognition.RecognizeCompletedEventArgs.Result" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute FrameworkAlternate="netframework-4.0">
          <AttributeName>get: System.Runtime.TargetedPatchingOptOut("Performance critical to inline this type of method across NGen image boundaries")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="eeb6f-134">認識結果を取得します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-134">Gets the recognition result.</span></span></summary>
        <value><span data-ttu-id="eeb6f-135">認識操作が成功した場合は認識結果。それ以外の場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-135">The recognition result if the recognition operation succeeded; otherwise, <see langword="null" />.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="eeb6f-136"><xref:System.Speech.Recognition.RecognitionResult>から派生したオブジェクト<xref:System.Speech.Recognition.RecognizedPhrase>認識操作によって返される語句の完全な情報が含まれています。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-136">The <xref:System.Speech.Recognition.RecognitionResult> object derives from <xref:System.Speech.Recognition.RecognizedPhrase> and contains full information about a phrase returned by a recognition operation.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="eeb6f-137">次の例は、音声認識文法の非同期音声認識を実行を使用して、<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType>インプロセス レコグナイザーを持つメソッド。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-137">The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=nameWithType> method with the in-process recognizer.</span></span> <span data-ttu-id="eeb6f-138">この例では<xref:System.Speech.Recognition.Choices>と<xref:System.Speech.Recognition.GrammarBuilder>に構築する前に、音声認識文法を作成するオブジェクト、<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-138">The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object.</span></span> <span data-ttu-id="eeb6f-139">ハンドラーを<xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType>イベントは、コンソールに認識操作に関する情報を出力します。</span><span class="sxs-lookup"><span data-stu-id="eeb6f-139">A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=nameWithType> event outputs information about the recognition operation to the console.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognitionEngine recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a SpeechRecognitionEngine object and set its input.  
      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo("en-US"));  
      recognizer.SetInputToDefaultAudioDevice();  
  
      // Configure recognition parameters.  
      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  
      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  
      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  
      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted +=  
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the RecognizeCompleted event.  
      recognizer.RecognizeCompleted +=   
        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  
  
      // Create a speech recognition grammar and build it into a Grammar object.  
      Choices bankingMenu = new Choices(new string[]   
      { "Access accounts", "Transfer funds", "Pay bills", "Get loan balance" });  
      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  
      Grammar bankGrammar = new Grammar(banking);  
      bankGrammar.Name = "Banking Menu";  
  
      // Load the Grammar objects to the recognizer.  
      recognizer.LoadGrammarAsync(bankGrammar);  
  
      // Start asynchronous, continuous recognition.  
      recognizer.RecognizeAsync();  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Handle the RecognizeCompleted event.  
    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  
    {  
      if (e.Error != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted, error occurred during recognition: {0}", e.Error);  
        return;  
      }  
  
      if (e.InitialSilenceTimeout || e.BabbleTimeout)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).",  
          e.BabbleTimeout, e.InitialSilenceTimeout);  
        return;  
      }  
  
      if (e.InputStreamEnded)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).",  
          e.AudioPosition, e.InputStreamEnded);  
      }  
  
      if (e.Result != null)  
      {  
        Console.WriteLine(  
          "RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).",  
          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  
      }  
  
      else  
      {  
        Console.WriteLine("RecognizeCompleted: No result.");  
      }   
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      bool grammarEnabled = e.Grammar.Enabled;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded and {2} enabled.", grammarName,   
        (grammarLoaded) ? "is" : "is not", (grammarEnabled) ? "is" : "is not");  
    }  
  }            
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted" />
      </Docs>
    </Member>
  </Members>
</Type>